{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc4f017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "839a3059",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Admission_Predict_Ver1.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dbad35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Serial No.",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GRE Score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TOEFL Score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "University Rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SOP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LOR ",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CGPA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Research",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Chance of Admit ",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "23e1fd76-2b3e-4ded-88fb-ed8a7bf1c969",
       "rows": [
        [
         "0",
         "1",
         "337",
         "118",
         "4",
         "4.5",
         "4.5",
         "9.65",
         "1",
         "0.92"
        ],
        [
         "1",
         "2",
         "324",
         "107",
         "4",
         "4.0",
         "4.5",
         "8.87",
         "1",
         "0.76"
        ],
        [
         "2",
         "3",
         "316",
         "104",
         "3",
         "3.0",
         "3.5",
         "8.0",
         "1",
         "0.72"
        ],
        [
         "3",
         "4",
         "322",
         "110",
         "3",
         "3.5",
         "2.5",
         "8.67",
         "1",
         "0.8"
        ],
        [
         "4",
         "5",
         "314",
         "103",
         "2",
         "2.0",
         "3.0",
         "8.21",
         "0",
         "0.65"
        ],
        [
         "5",
         "6",
         "330",
         "115",
         "5",
         "4.5",
         "3.0",
         "9.34",
         "1",
         "0.9"
        ],
        [
         "6",
         "7",
         "321",
         "109",
         "3",
         "3.0",
         "4.0",
         "8.2",
         "1",
         "0.75"
        ],
        [
         "7",
         "8",
         "308",
         "101",
         "2",
         "3.0",
         "4.0",
         "7.9",
         "0",
         "0.68"
        ],
        [
         "8",
         "9",
         "302",
         "102",
         "1",
         "2.0",
         "1.5",
         "8.0",
         "0",
         "0.5"
        ],
        [
         "9",
         "10",
         "323",
         "108",
         "3",
         "3.5",
         "3.0",
         "8.6",
         "0",
         "0.45"
        ],
        [
         "10",
         "11",
         "325",
         "106",
         "3",
         "3.5",
         "4.0",
         "8.4",
         "1",
         "0.52"
        ],
        [
         "11",
         "12",
         "327",
         "111",
         "4",
         "4.0",
         "4.5",
         "9.0",
         "1",
         "0.84"
        ],
        [
         "12",
         "13",
         "328",
         "112",
         "4",
         "4.0",
         "4.5",
         "9.1",
         "1",
         "0.78"
        ],
        [
         "13",
         "14",
         "307",
         "109",
         "3",
         "4.0",
         "3.0",
         "8.0",
         "1",
         "0.62"
        ],
        [
         "14",
         "15",
         "311",
         "104",
         "3",
         "3.5",
         "2.0",
         "8.2",
         "1",
         "0.61"
        ],
        [
         "15",
         "16",
         "314",
         "105",
         "3",
         "3.5",
         "2.5",
         "8.3",
         "0",
         "0.54"
        ],
        [
         "16",
         "17",
         "317",
         "107",
         "3",
         "4.0",
         "3.0",
         "8.7",
         "0",
         "0.66"
        ],
        [
         "17",
         "18",
         "319",
         "106",
         "3",
         "4.0",
         "3.0",
         "8.0",
         "1",
         "0.65"
        ],
        [
         "18",
         "19",
         "318",
         "110",
         "3",
         "4.0",
         "3.0",
         "8.8",
         "0",
         "0.63"
        ],
        [
         "19",
         "20",
         "303",
         "102",
         "3",
         "3.5",
         "3.0",
         "8.5",
         "0",
         "0.62"
        ],
        [
         "20",
         "21",
         "312",
         "107",
         "3",
         "3.0",
         "2.0",
         "7.9",
         "1",
         "0.64"
        ],
        [
         "21",
         "22",
         "325",
         "114",
         "4",
         "3.0",
         "2.0",
         "8.4",
         "0",
         "0.7"
        ],
        [
         "22",
         "23",
         "328",
         "116",
         "5",
         "5.0",
         "5.0",
         "9.5",
         "1",
         "0.94"
        ],
        [
         "23",
         "24",
         "334",
         "119",
         "5",
         "5.0",
         "4.5",
         "9.7",
         "1",
         "0.95"
        ],
        [
         "24",
         "25",
         "336",
         "119",
         "5",
         "4.0",
         "3.5",
         "9.8",
         "1",
         "0.97"
        ],
        [
         "25",
         "26",
         "340",
         "120",
         "5",
         "4.5",
         "4.5",
         "9.6",
         "1",
         "0.94"
        ],
        [
         "26",
         "27",
         "322",
         "109",
         "5",
         "4.5",
         "3.5",
         "8.8",
         "0",
         "0.76"
        ],
        [
         "27",
         "28",
         "298",
         "98",
         "2",
         "1.5",
         "2.5",
         "7.5",
         "1",
         "0.44"
        ],
        [
         "28",
         "29",
         "295",
         "93",
         "1",
         "2.0",
         "2.0",
         "7.2",
         "0",
         "0.46"
        ],
        [
         "29",
         "30",
         "310",
         "99",
         "2",
         "1.5",
         "2.0",
         "7.3",
         "0",
         "0.54"
        ],
        [
         "30",
         "31",
         "300",
         "97",
         "2",
         "3.0",
         "3.0",
         "8.1",
         "1",
         "0.65"
        ],
        [
         "31",
         "32",
         "327",
         "103",
         "3",
         "4.0",
         "4.0",
         "8.3",
         "1",
         "0.74"
        ],
        [
         "32",
         "33",
         "338",
         "118",
         "4",
         "3.0",
         "4.5",
         "9.4",
         "1",
         "0.91"
        ],
        [
         "33",
         "34",
         "340",
         "114",
         "5",
         "4.0",
         "4.0",
         "9.6",
         "1",
         "0.9"
        ],
        [
         "34",
         "35",
         "331",
         "112",
         "5",
         "4.0",
         "5.0",
         "9.8",
         "1",
         "0.94"
        ],
        [
         "35",
         "36",
         "320",
         "110",
         "5",
         "5.0",
         "5.0",
         "9.2",
         "1",
         "0.88"
        ],
        [
         "36",
         "37",
         "299",
         "106",
         "2",
         "4.0",
         "4.0",
         "8.4",
         "0",
         "0.64"
        ],
        [
         "37",
         "38",
         "300",
         "105",
         "1",
         "1.0",
         "2.0",
         "7.8",
         "0",
         "0.58"
        ],
        [
         "38",
         "39",
         "304",
         "105",
         "1",
         "3.0",
         "1.5",
         "7.5",
         "0",
         "0.52"
        ],
        [
         "39",
         "40",
         "307",
         "108",
         "2",
         "4.0",
         "3.5",
         "7.7",
         "0",
         "0.48"
        ],
        [
         "40",
         "41",
         "308",
         "110",
         "3",
         "3.5",
         "3.0",
         "8.0",
         "1",
         "0.46"
        ],
        [
         "41",
         "42",
         "316",
         "105",
         "2",
         "2.5",
         "2.5",
         "8.2",
         "1",
         "0.49"
        ],
        [
         "42",
         "43",
         "313",
         "107",
         "2",
         "2.5",
         "2.0",
         "8.5",
         "1",
         "0.53"
        ],
        [
         "43",
         "44",
         "332",
         "117",
         "4",
         "4.5",
         "4.0",
         "9.1",
         "0",
         "0.87"
        ],
        [
         "44",
         "45",
         "326",
         "113",
         "5",
         "4.5",
         "4.0",
         "9.4",
         "1",
         "0.91"
        ],
        [
         "45",
         "46",
         "322",
         "110",
         "5",
         "5.0",
         "4.0",
         "9.1",
         "1",
         "0.88"
        ],
        [
         "46",
         "47",
         "329",
         "114",
         "5",
         "4.0",
         "5.0",
         "9.3",
         "1",
         "0.86"
        ],
        [
         "47",
         "48",
         "339",
         "119",
         "5",
         "4.5",
         "4.0",
         "9.7",
         "0",
         "0.89"
        ],
        [
         "48",
         "49",
         "321",
         "110",
         "3",
         "3.5",
         "5.0",
         "8.85",
         "1",
         "0.82"
        ],
        [
         "49",
         "50",
         "327",
         "111",
         "4",
         "3.0",
         "4.0",
         "8.4",
         "1",
         "0.78"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 500
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>497</td>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0             1        337          118                  4  4.5   4.5  9.65   \n",
       "1             2        324          107                  4  4.0   4.5  8.87   \n",
       "2             3        316          104                  3  3.0   3.5  8.00   \n",
       "3             4        322          110                  3  3.5   2.5  8.67   \n",
       "4             5        314          103                  2  2.0   3.0  8.21   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "495         496        332          108                  5  4.5   4.0  9.02   \n",
       "496         497        337          117                  5  5.0   5.0  9.87   \n",
       "497         498        330          120                  5  4.5   5.0  9.56   \n",
       "498         499        312          103                  4  4.0   5.0  8.43   \n",
       "499         500        327          113                  4  4.5   4.5  9.04   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "0           1              0.92  \n",
       "1           1              0.76  \n",
       "2           1              0.72  \n",
       "3           1              0.80  \n",
       "4           0              0.65  \n",
       "..        ...               ...  \n",
       "495         1              0.87  \n",
       "496         1              0.96  \n",
       "497         1              0.93  \n",
       "498         0              0.73  \n",
       "499         0              0.84  \n",
       "\n",
       "[500 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63d2e2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "99d9bf9b-7329-4384-b63c-6f3746cf4425",
       "rows": [
        [
         "Serial No.",
         "0"
        ],
        [
         "GRE Score",
         "0"
        ],
        [
         "TOEFL Score",
         "0"
        ],
        [
         "University Rating",
         "0"
        ],
        [
         "SOP",
         "0"
        ],
        [
         "LOR ",
         "0"
        ],
        [
         "CGPA",
         "0"
        ],
        [
         "Research",
         "0"
        ],
        [
         "Chance of Admit ",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 9
       }
      },
      "text/plain": [
       "Serial No.           0\n",
       "GRE Score            0\n",
       "TOEFL Score          0\n",
       "University Rating    0\n",
       "SOP                  0\n",
       "LOR                  0\n",
       "CGPA                 0\n",
       "Research             0\n",
       "Chance of Admit      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a813ad11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b03b7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18c5ba01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Serial No.', 'GRE Score', 'TOEFL Score', 'University Rating', 'SOP',\n",
       "       'LOR ', 'CGPA', 'Research', 'Chance of Admit '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3253ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Serial No.'] , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65b30259",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[[ 'GRE Score', 'TOEFL Score', 'University Rating', 'SOP',\n",
    "       'LOR ', 'CGPA', 'Research']]\n",
    "y=df['Chance of Admit ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5ef81c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "361aa92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test=train_test_split(X, y , random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a76e1730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf5a2839",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled=scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d145f36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "169fc5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79ae6e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(7 , activation='relu', input_dim=7))\n",
    "model.add(Dense(7 , activation='relu'))\n",
    "model.add(Dense(1 , activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ca6b1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m8\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m14\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m8\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> (1.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m272\u001b[0m (1.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">142</span> (568.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m142\u001b[0m (568.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> (524.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m130\u001b[0m (524.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6fc5547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "060ea1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - loss: 0.2381 - val_loss: 0.1722\n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.1052 - val_loss: 0.0543\n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0231 - val_loss: 0.0074\n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0119 - val_loss: 0.0125\n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0112 - val_loss: 0.0068\n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0074 - val_loss: 0.0075\n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0075 - val_loss: 0.0068\n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0068 - val_loss: 0.0060\n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0066 - val_loss: 0.0058\n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0063 - val_loss: 0.0057\n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0039 - val_loss: 0.0035\n"
     ]
    }
   ],
   "source": [
    "history = model.fit (X_train_scaled , y_train , epochs=100 , validation_split=0.2 , verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23f8b94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15f62382",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d35c3511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8139372284010954"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "115c7ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26ee8e2fb10>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e038acaf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
